master:
  prefix: deep_ # bert | xlnet | word2vec | fasttext
  release_mode: patch
  description: # This is model description
  train_key: train
  dev_key: dev
  save_path: # save folder path
  sampling: true
  labels: Uncorrelated_Contra Sarcasm_Pro_Neutral_Contra_Pro Sarcasm
  label_key: Label
  key_list: Tweet_Comment
loader:
  data_path: / # path to data
  tokenizer_type: bert # bert | xlnet | word2vec | fasttext
  model_name: indobenchmark/indobert-base-p2 # indobenchmark/indobert-base-p2 | malay-huggingface/xlnet-tiny-bahasa-cased
  tokenizer_config:
    max_length: 512
    padding: max_length
    return_tensors: tf
    truncation: true
    # for word vectors
    model_type: word2vec # word2vec | fasttext
    is_pretrained: true
    model_path: / #path to model
    log_oov: false
    vector_size: 100 
    max_sequence: 256 # max_length/2
    model_behavior: concat # concat | combine
classifier:
  type: bert # bert | xlnet | word2vec | fasttext
  model_name: indobenchmark/indobert-base-p2 | malay-huggingface/xlnet-tiny-bahasa-cased
  recurrent_layer: lstm | bilstm | gru | bigru
  recurrent_unit: 64
  recurrent_dropout: 0.4
trainer:
  batch_size: 4
  learning_rate: 5.0e-05
  epochs: 20
  gpus: 1 | 2 | 3




